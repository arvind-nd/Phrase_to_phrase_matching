wandb=False
competition='PPTPM'
_wandb_kernel='arvind'
debug=False
apex=True
print_freq=100
num_workers=4
model="roberta-large"
scheduler='cosine' # ['linear', 'cosine']
batch_scheduler=True
num_cycles=0.5
num_warmup_steps=0
epochs=5
encoder_lr=9e-6
decoder_lr=9e-6
min_lr=3e-7
eps=3e-7
betas=(0.9, 0.999)
batch_size=16
fc_dropout=0.1
target_size=1
max_len=200
weight_decay=0.01
gradient_accumulation_steps=1
max_grad_norm=1000
seed=42
n_fold=5
trn_fold=[0, 1, 2, 3, 4]
fold = 1
train=True
train_data_path = "../input/uspptpm-train-4-folds-datasgkf/USPPTPM_skf_train_5folds.csv"
cpc_text_path = "../input/uspptpm-data/cpc_texts.pth"
